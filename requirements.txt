torch>=2.0.0
numpy>=1.24.0
tqdm>=4.65.0
transformers>=4.30.0
datasets>=2.12.0
accelerate>=0.20.0
wandb>=0.15.0
sentencepiece>=0.1.99
tokenizers>=0.13.3
einops>=0.6.1 